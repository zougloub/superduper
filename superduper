#!/usr/bin/env python
# -*- coding: utf-8 vi:ts=4:noet
# SuperDuper!
# PYTHON_ARGCOMPLETE_OK

import sys, os, argparse, pickle, pprint

import deduppy

def printf(x):
	if verbose > 0:
		sys.stdout.write(x)
		sys.stdout.flush()

def main():

	global verbose

	parser = argparse.ArgumentParser(
	 usage="%prog [options] <dirs>\n%prog --help for details",
	 version="%prog v0.2"
	)

	parser.add_argument(
	 "dirs",
	 nargs="*",
	 help="directories where to look for duplicates",
	)

	parser.add_argument(
	 "-q", "--quiet",
	 action="store_false",
	 dest="verbose",
	 default=True,
	 help="don't print status messages to stdout"
	)

	parser.add_argument(
	 "--hardlink",
	 action="store_true",
	 help="hard-link identical files",
	)

	parser.add_argument(
	 "--dump",
	 help="dump list of dupes to file",
	)

	parser.add_argument(
	 "--load",
	 help="load list of dupes from file",
	)

	parser.add_argument(
	 "--ignore-access-errors",
	 action="store_true",
	 help="ignore filesystem access errors that happen in stat() or open()",
	)

	parser.add_argument(
	 "--shortcut-file-read-max",
	 default=-1,
	 type=int,
	 help="number of identical bytes to read on each file before concluding they are the same",
	)

	try:
		import argcomplete
		argcomplete.autocomplete(parser)
	except:
		pass

	args = parser.parse_args()

	if args.dirs == []:
		parser.print_version()
		parser.print_usage()
		os._exit(1)

	verbose = 1 if args.verbose else 0

	if args.load:
		printf("Loading dupe list from file...")
		with open(args.load, "rb") as f:
			alldupes = pickle.load(f)
		printf("OK\n")
	else:

		def ign():
			"""
			Ignore file access errors
			"""
			if not args.ignore_access_errors:
				return False

			if sys.exc_type == OSError and sys.exc_value.errno == 16:
				# device or resource busy (gdrive)
				return True
			elif sys.exc_type == IOError and sys.exc_value.errno == 16:
				# device or resource busy (gdrive)
				return True


		d = deduppy.DupFinder(ignore_exc=ign, file_read_max=args.shortcut_file_read_max)
		d.printf = printf
  
		for arg in args.dirs:
			printf("Starting to look for files in %s\n" % arg)
			if os.path.isdir(arg):
				s = deduppy.FileStore_FS(arg, ignore_exc=ign)
				for f in s.walk():
					printf("- %s\n" % f)
					d.add(f)
			elif arg.endswith(".zip"):
				s = deduppy.FileStore_ZipFile(arg)
				for f in s.walk():
					printf("- %s\n" % f)
					d.add(f)
			else:
				raise RuntimeError("%s is not supported" % arg)
			printf("Finished to look for files in %s\n" % arg)

		printf("Starting to identify duplicates\n")
		alldupes = d.execute()
		printf("Finished to identify duplicates\n")

		printf("Total files: %d\n" % d._num_files)
		printf("Bytes read: %d\n" % d._bytes_read)

	if args.dump:
		with open(args.dump, "wb") as f:
			pickle.dump(alldupes, f)

	#print("Alldupes=%s" % pprint.pformat(alldupes, depth=150, width=10000))
	#return

	printf("Report:\n")

	for size, dupes in sorted(alldupes):
		printf("- size %s\n" % size)

		for files in dupes:
			if args.hardlink:
				orig = files[0]
				for f in files[1:]:
					printf("Link %s <- %s ..." % (orig, f))
					if not os.path.exists(f) or not os.path.exists(orig):
						continue
					os.rename(f, f + ".dupe")
					os.link(orig, f)
					os.unlink(f + ".dupe")
					printf("OK\n")
			else:
				for f in files:
					printf("\t%s" % f) #pprint.pprint(f, depth=150, width=1000))
			printf("\n")

if __name__ == "__main__":
	main()

